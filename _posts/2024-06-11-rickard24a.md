---
title: Learning Robust Policies for Uncertain Parametric Markov Decision Processes
abstract: Synthesising verifiably correct controllers for dynamical systems is crucial
  for safety-critical problems. To achieve this, it is important to account for uncertainty
  in a robust manner, while at the same time it is often of interest to avoid being
  overly conservative with the view of achieving a better cost. We propose a method
  for verifiably safe policy synthesis for a class of finite state models, under the
  presence of structural uncertainty. In particular, we consider uncertain parametric
  Markov decision processes (upMDPs), a special class of Markov decision processes,
  with parameterised transition functions, where such parameters are drawn from a
  (potentially) unknown distribution. Our framework leverages recent advancements
  in the so-called scenario approach theory, where we represent the uncertainty by
  means of scenarios, and provide guarantees on synthesised policies satisfying probabilistic
  computation tree logic (PCTL) formulae. We consider several common benchmarks/problems
  and compare our work to recent developments for verifying upMDPs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rickard24a
month: 0
tex_title: "{Learning Robust Policies for Uncertain Parametric Markov Decision Processes}"
firstpage: 1
lastpage: 14
page: 1-14
order: 1
cycles: false
bibtex_author: Rickard, Luke and Abate, Alessandro and Margellos, Kostas
author:
- given: Luke
  family: Rickard
- given: Alessandro
  family: Abate
- given: Kostas
  family: Margellos
date: 2024-06-11
address:
container-title: Proceedings of the 6th Annual Learning for Dynamics & Control Conference
volume: '242'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 11
pdf: https://proceedings.mlr.press/v242/rickard24a/rickard24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
