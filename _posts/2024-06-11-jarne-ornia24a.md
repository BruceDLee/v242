---
title: Bounded robustness in reinforcement learning via lexicographic objectives
abstract: 'Policy robustness in Reinforcement Learning may not be desirable at any
  cost: the alterations caused by robustness requirements from otherwise optimal policies
  should be explainable, quantifiable and formally verifiable. In this work we study
  how policies can be maximally robust to arbitrary observational noise by analysing
  how they are altered by this noise through a stochastic linear operator interpretation
  of the disturbances, and establish connections between robustness and properties
  of the noise kernel and of the underlying MDPs. Then, we construct sufficient conditions
  for policy robustness, and propose a robustness-inducing scheme, applicable to any
  policy gradient algorithm, that formally trades off expected policy utility for
  robustness through lexicographic optimisation, while preserving convergence and
  sub-optimality in the policy synthesis.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jarne-ornia24a
month: 0
tex_title: "Bounded robustness in reinforcement learning via lexicographic objectives"
firstpage: 954
lastpage: 967
page: 954-967
order: 954
cycles: false
bibtex_author: Jarne Ornia, Daniel and Romao, Licio and Hammond, Lewis and Jr, Manuel
  Mazo and Abate, Alessandro
author:
- given: Daniel
  family: Jarne Ornia
- given: Licio
  family: Romao
- given: Lewis
  family: Hammond
- given: Manuel Mazo
  family: Jr
- given: Alessandro
  family: Abate
date: 2024-06-11
address:
container-title: Proceedings of the 6th Annual Learning for Dynamics & Control Conference
volume: '242'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 11
pdf: https://proceedings.mlr.press/v242/jarne-ornia24a/jarne-ornia24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
