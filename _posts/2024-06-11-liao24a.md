---
title: Error bounds, PL condition, and quadratic growth for weakly convex functions,
  and linear convergences of proximal point methods
abstract: Many machine learning problems lack strong convexity properties. Fortunately,
  recent studies have revealed that first-order algorithms also enjoy linear convergences
  under various weaker regularity conditions. While the relationship among different
  conditions for convex and smooth functions is well understood, it is not the case
  for the nonsmooth setting. In this paper, we go beyond convexity and smoothness,
  and clarify the connections among common regularity conditions (including strong
  convexity, restricted secant inequality, subdifferential error bound, Polyak-{≈Å}ojasiewic
  inequality, and quadratic growth) in the class of weakly convex functions. In addition,
  we present a simple and modular proof for the linear convergence of the proximal
  point method (PPM) for convex (possibly nonsmooth) optimization using these regularity
  conditions. The linear convergence also holds when the subproblems of PPM are solved
  inexactly with a proper control of inexactness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liao24a
month: 0
tex_title: "Error bounds, {PL} condition, and quadratic growth for weakly convex functions,
  and linear convergences of proximal point methods"
firstpage: 993
lastpage: 1005
page: 993-1005
order: 993
cycles: false
bibtex_author: Liao, Feng-Yi and Ding, Lijun and Zheng, Yang
author:
- given: Feng-Yi
  family: Liao
- given: Lijun
  family: Ding
- given: Yang
  family: Zheng
date: 2024-06-11
address:
container-title: Proceedings of the 6th Annual Learning for Dynamics & Control Conference
volume: '242'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 11
pdf: https://proceedings.mlr.press/v242/liao24a/liao24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
