---
title: An efficient data-based off-policy Q-learning algorithm for optimal output
  feedback control of linear systems
booktitle: Proceedings of the 6th Annual Learning for Dynamics \& Control Conference
abstract: In this paper, we present a Q-learning algorithm to solve the optimal output
  regulation problem for discrete-time LTI systems. This off-policy algorithm only
  relies on using persistently exciting input-output data, measured offline. No model
  knowledge or state measurements are needed and the obtained optimal policy only
  uses past input-output information. Moreover, our formulation of the proposed algorithm
  renders it computationally efficient. We provide conditions that guarantee the convergence
  of the algorithm to the optimal solution. Finally, the performance of our method
  is compared to existing algorithms in the literature.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alsalti24a
month: 0
tex_title: "{An efficient data-based off-policy Q-learning algorithm for optimal output
  feedback control of linear systems}"
firstpage: 1
lastpage: 12
page: 1-12
order: 1
cycles: false
bibtex_author: Alsalti, Mohammad and Lopez, Victor G. and M\"{u}ller, Matthias A.
author:
- given: Mohammad
  family: Alsalti
- given: Victor G.
  family: Lopez
- given: Matthias A.
  family: MÃ¼ller
date: 2024-06-11
address:
container-title: Proceedings of the 6th Annual Learning for Dynamics \& Control Conference
volume: '242'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 11
pdf: https://proceedings.mlr.press/v242/alsalti24a/alsalti24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
