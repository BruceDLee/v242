---
title: Hamiltonian GAN
booktitle: Proceedings of the 6th Annual Learning for Dynamics \& Control Conference
abstract: A growing body of work leverages the Hamiltonian formalism as an inductive
  bias for physically plausible neural network based video generation. The structure
  of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and
  imposes a phase-space interpretation on the low-dimensional manifold underlying
  the input video. While this interpretation has the potential to facilitate the integration
  of learned representations in downstream tasks, existing methods are limited in
  their applicability as they require a structural prior for the configuration space
  at design time. In this work, we present a GAN-based video generation pipeline with
  a learned configuration space map and Hamiltonian neural network motion model, to
  learn a representation of the configuration space from data. We train our model
  with a physics-inspired cyclic-coordinate loss function which encourages a minimal
  representation of the configuration space and improves interpretability. We demonstrate
  the efficacy and advantages of our approach on the Hamiltonian Dynamics Suite Toy
  Physics dataset.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: allen-blanchette24a
month: 0
tex_title: "{Hamiltonian GAN}"
firstpage: 1
lastpage: 13
page: 1-13
order: 1
cycles: false
bibtex_author: Allen-Blanchette, Christine
author:
- given: Christine
  family: Allen-Blanchette
date: 2024-06-11
address:
container-title: Proceedings of the 6th Annual Learning for Dynamics \& Control Conference
volume: '242'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 11
pdf: https://proceedings.mlr.press/v242/allen-blanchette24a/allen-blanchette24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
